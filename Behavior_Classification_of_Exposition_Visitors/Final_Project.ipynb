{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8cf7b3",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "Team 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c964f",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f261b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Visitor:\n",
    "    def __init__(self, mac_hash : str, label: int = -1) -> None:\n",
    "        self.mac_hash = mac_hash\n",
    "        self.label = label\n",
    "        self.sniffer_loc_list = []\n",
    "        self.created_time_list = []\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'{self.mac_hash} {self.label} {self.sniffer_loc_list}'\n",
    "\n",
    "    def add_loc_and_time(self, sniffer_loc: int, created_time: str) -> None:\n",
    "        self.sniffer_loc_list.append(sniffer_loc)\n",
    "        self.created_time_list.append(created_time)\n",
    "\n",
    "def parse_label_and_feature(label_filepath: str, feature_filepath: str) -> dict:\n",
    "    mac_hash_to_visitor = {}\n",
    "    label_array = pd.read_csv(label_filepath, sep=',').to_numpy()\n",
    "    for data in label_array:\n",
    "        mac_hash = data[0]\n",
    "        label = int(data[1]) if len(data) == 2 else -1\n",
    "        mac_hash_to_visitor[mac_hash] = Visitor(mac_hash, label)\n",
    "\n",
    "    feature_array = pd.read_csv(feature_filepath, sep=',').to_numpy()\n",
    "    for mac_hash, sniffer_loc, created_time in feature_array:\n",
    "        mac_hash_to_visitor[mac_hash].add_loc_and_time(sniffer_loc, created_time)\n",
    "    return mac_hash_to_visitor\n",
    "\n",
    "train_mac_hash_to_visitor = parse_label_and_feature('training-label.csv', 'train.csv')\n",
    "test_mac_hash_to_visitor = parse_label_and_feature('submit_samples.csv', 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daba38a",
   "metadata": {},
   "source": [
    "## Define Evaluating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4747807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    log_prob_sum = 0\n",
    "    for i, prob in enumerate(y_pred):\n",
    "        y_prob = prob[int(y_true[i])]\n",
    "        y_prob = 0.2 if y_prob == 0 else y_prob\n",
    "        log_prob_sum += np.log(y_prob)\n",
    "    return float(-log_prob_sum / y_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92d59d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d761d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def to_second(time: str) -> int:\n",
    "    h, m, s = time.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "def get_duration_list(sniffer_loc_list: list, created_time_list: list) -> np.ndarray:\n",
    "    loc_and_time_list = list(zip(sniffer_loc_list, created_time_list))\n",
    "    loc_and_time_list.sort(key=lambda s : s[1])\n",
    "\n",
    "    duration_list = np.zeros((14,), dtype=int)\n",
    "    for i in range(len(loc_and_time_list) - 1):\n",
    "        cur_loc = loc_and_time_list[i][0]\n",
    "        cur_date, cur_time = str(loc_and_time_list[i][1]).split(' ')\n",
    "        next_date, next_time = str(loc_and_time_list[i + 1][1]).split(' ')\n",
    "\n",
    "        duration = to_second(next_time) - to_second(cur_time)\n",
    "        duration_list[int(cur_loc) - 1] = 1 if next_date != cur_date or duration == 0 else duration\n",
    "    duration_list[int(loc_and_time_list[-1][0]) - 1] = 1\n",
    "    return duration_list\n",
    "\n",
    "def feature_preprocess(mac_hash_to_visitor: dict) -> np.ndarray:\n",
    "    sniffer_loc_to_group = { 1: -1,  2: 0,  3: -1,  4:  0,  5:  0,  6:  0,  7:  1,\n",
    "                             8: -1,  9: 2, 10:  2, 11:  2, 12:  3, 13:  1, 14:  3}\n",
    "    features = np.zeros((len(mac_hash_to_visitor), 22), dtype=int)\n",
    "    for i, (_, visitor) in enumerate(mac_hash_to_visitor.items()):\n",
    "        for sniffer_loc in visitor.sniffer_loc_list:\n",
    "            features[i][int(sniffer_loc) - 1] = 1\n",
    "        features[i][14] = len(visitor.sniffer_loc_list)\n",
    "        for sniffer_loc in visitor.sniffer_loc_list:\n",
    "            if sniffer_loc_to_group[int(sniffer_loc)] != -1:\n",
    "                features[i][15 + sniffer_loc_to_group[int(sniffer_loc)]] += 1\n",
    "        date, time = str(visitor.created_time_list[0]).split(' ')\n",
    "        day = int(date.split('-')[2])\n",
    "        features[i][19 + (day - 6)] = 1\n",
    "\n",
    "        # duration_list = get_duration_list(visitor.sniffer_loc_list, visitor.created_time_list)\n",
    "        # features[i][0:14] = duration_list\n",
    "        # features[i][14] = np.sum(duration_list)\n",
    "        # for sniffer_loc in visitor.sniffer_loc_list:\n",
    "        #     if sniffer_loc_to_group[int(sniffer_loc)] != -1:\n",
    "        #         features[i][15 + sniffer_loc_to_group[int(sniffer_loc)]] += duration_list[int(sniffer_loc) - 1]\n",
    "        # date, time = str(visitor.created_time_list[0]).split(' ')\n",
    "        # day = int(date.split('-')[2])\n",
    "        # features[i][19 + (day - 6)] = 1\n",
    "    return features\n",
    "\n",
    "train_features = feature_preprocess(train_mac_hash_to_visitor)\n",
    "train_labels = np.zeros((len(train_mac_hash_to_visitor),), dtype=int)\n",
    "for i, (_, visitor) in enumerate(train_mac_hash_to_visitor.items()):\n",
    "    train_labels[i] = int(visitor.label)\n",
    "test_features = feature_preprocess(test_mac_hash_to_visitor)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "\n",
    "train_features = scaler.transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(train_features, train_labels, test_size=0.2, random_state=1)\n",
    "X_test = test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6b5f30",
   "metadata": {},
   "source": [
    "## Probability Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0597b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_postprocess(y_pred: np.ndarray, y_pred_prob: np.ndarray, threshold: float = 0.99) -> np.ndarray:\n",
    "    y_prob_post = np.copy(y_pred_prob)\n",
    "    for i, y in enumerate(y_pred):\n",
    "        if y_prob_post[i][int(y)] >= threshold:\n",
    "            y_prob_post[i] = np.eye(1, y_prob_post.shape[1], int(y))[0]\n",
    "    return y_prob_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a8534",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron\n",
    "* Reference:\\\n",
    "    [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dc9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989224\n",
      "Log-loss: 0.029678\n",
      "Log-loss: 0.026509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = mlp.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890ab06",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "* Reference:\\\n",
    "    [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870975f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.979885\n",
      "Log-loss: 0.036367\n",
      "Log-loss: 0.036367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = decision_tree.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230d31d",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "* Reference:\\\n",
    "    [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0016b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987787\n",
      "Log-loss: 0.072180\n",
      "Log-loss: 0.069622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = random_forest.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d22a2",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting (XGBoost)\n",
    "* Install in conda:\n",
    "```\n",
    "    $ conda install -c conda-forge py-xgboost\n",
    "```\n",
    "* Reference:\\\n",
    "    [XGBClassifier](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6649a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eric\\miniconda3\\envs\\ml\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987787\n",
      "Log-loss: 0.031896\n",
      "Log-loss: 0.029086\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgboost = XGBClassifier(use_label_encoder=False)\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgboost.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = xgboost.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb77b49",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "* Install in conda:\n",
    "```\n",
    "    $ conda config --add channels conda-forge\n",
    "    $ conda install catboost\n",
    "```\n",
    "* Reference:\\\n",
    "    [CatBoostClassifier](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa74162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987069\n",
      "Log-loss: 0.034429\n",
      "Log-loss: 0.031379\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cat_boost = CatBoostClassifier(verbose=False)\n",
    "cat_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat_boost.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = cat_boost.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73da8e",
   "metadata": {},
   "source": [
    "## Voting\n",
    "* Reference:\\\n",
    "    [VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "732f03d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.990661\n",
      "Log-loss: 0.028647\n",
      "Log-loss: 0.028026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('mlp', mlp), ('decision_tree', decision_tree), ('random_forest', random_forest), ('xgboost', xgboost), ('cat_boost', cat_boost)],\n",
    "    voting='soft',\n",
    "    weights=[1, 0, 0, 0.9, 1]\n",
    ")\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "y_pred = voting.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = voting.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f51df",
   "metadata": {},
   "source": [
    "## Choose a Model to Predict Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21756987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.990661\n",
      "Log-loss: 0.028647\n",
      "Log-loss: 0.028026\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "## choose model\n",
    "model = voting\n",
    "\n",
    "## save model\n",
    "joblib.dump(model, 'checkpoint/ckpt.tar.gz')\n",
    "\n",
    "## load model\n",
    "# model = joblib.load('checkpoint/ckpt_0.0407222.tar.gz')\n",
    "\n",
    "## evaluate model\n",
    "y_pred = model.predict(X_validate)\n",
    "print(f'Accuracy: {accuracy_score(y_validate, y_pred):f}')\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_validate)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_pred_prob):f}')\n",
    "\n",
    "y_prob_post = prob_postprocess(y_pred, y_pred_prob)\n",
    "print(f'Log-loss: {log_loss(y_validate, y_prob_post):f}')\n",
    "\n",
    "## predict testing data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "y_pred_prob = prob_postprocess(y_pred, y_pred_prob)\n",
    "\n",
    "test_mac_hash_list = [visitor.mac_hash for _, visitor in test_mac_hash_to_visitor.items()]\n",
    "mac_hash_df = pd.DataFrame(test_mac_hash_list, columns=['mac_hash'])\n",
    "pred_prob_df = pd.DataFrame(y_pred_prob, columns=['C0', 'C1', 'C2', 'C3', 'C4'])\n",
    "pred_df = pd.concat([mac_hash_df, pred_prob_df], axis=1)\n",
    "pred_df.to_csv('result/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61c7aab724424b0567b462860f57c57d7e2713ced9fa1ccacef6f2077e18e32a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
